{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa27ec5b-9911-41da-8a50-7bc6a5db793d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 15:46:47.132090: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/ashpot/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13882354-34a2-4426-80d6-5dfe955a8f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset\n",
    "np.random.seed(2010)\n",
    "x_train = np.random.random((6000,10))\n",
    "y_train = np.random.randint(2, size=(6000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e29e75-257a-4d6f-b23f-7ff20d9c5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genrate dummy validation dataset\n",
    "x_val = np.random.random((2000,10))\n",
    "y_val = np.random.randint(2, size=(2000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f0282b-f9f6-4598-bad1-59bf43f4c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genrate dummy test data\n",
    "x_test = np.random.random((2000,10))\n",
    "y_test = np.random.randint(2, size=(2000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea41d5c6-907f-452d-8ff4-c44c6e7cf451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashpot/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "model.add(Dense(32,  activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8,  activation='relu'))\n",
    "model.add(Dense(4,  activation='relu'))\n",
    "model.add(Dense(1,  activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392ba4c3-efaa-4ab6-a2d5-b17aeb6b3c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: 0.6933 - val_accuracy: 0.4805 - val_loss: 0.6941\n",
      "Epoch 2/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4871 - loss: 0.6929 - val_accuracy: 0.4830 - val_loss: 0.6957\n",
      "Epoch 3/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5085 - loss: 0.6931 - val_accuracy: 0.4800 - val_loss: 0.6942\n",
      "Epoch 4/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: 0.6924 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 5/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5209 - loss: 0.6922 - val_accuracy: 0.5025 - val_loss: 0.6941\n",
      "Epoch 6/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5185 - loss: 0.6917 - val_accuracy: 0.4815 - val_loss: 0.6945\n",
      "Epoch 7/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: 0.6929 - val_accuracy: 0.5055 - val_loss: 0.6937\n",
      "Epoch 8/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5219 - loss: 0.6920 - val_accuracy: 0.5065 - val_loss: 0.6945\n",
      "Epoch 9/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5284 - loss: 0.6905 - val_accuracy: 0.5185 - val_loss: 0.6929\n",
      "Epoch 10/10\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5165 - loss: 0.6923 - val_accuracy: 0.4790 - val_loss: 0.6972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x135730af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c8035d-b828-4402-9c56-6756d5ec682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 0.6963\n",
      "[0.6949282288551331, 0.5105000138282776]\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb4b337-46f8-4ed1-bcd8-72fe9d15ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'compile_metrics']\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a9ed3-0945-4259-8822-ce171299c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd9d3ed-295c-4c9f-956e-fcb8842377d6",
   "metadata": {},
   "source": [
    "## Introduction to Training Deep Learning Models\n",
    "Deep learning models are trained using large datasets and computational techniques that adjust model parameters to minimize errors. The primary mechanism for this is backpropagation combined with gradient descent, allowing the model to learn from data iteratively.\n",
    "\n",
    "### Key Concepts:\n",
    "1. Neural Networks: Composed of layers of neurons with trainable parameters (weights & biases).\n",
    "2. Loss Function: Measures how far the model’s prediction is from the actual value.\n",
    "Optimization Algorithm: Adjusts weights to minimize loss (e.g., Gradient Descent).\n",
    "3. Epochs & Iterations: Number of times the model sees the entire dataset.\n",
    "4. Overfitting & Generalization: How well the model performs on unseen data.\n",
    "\n",
    "### Backpropagation & Gradient Descent (P.C 8.2.1)\n",
    "##### Understanding Backpropagation\n",
    "Backpropagation is a key algorithm used to train deep learning models by updating weights based on the loss function’s gradient.\n",
    "\n",
    "##### Steps of Backpropagation:\n",
    "1. Forward Propagation\n",
    "\n",
    "Inputs are passed through the network.\n",
    "Predictions are made using current weights.\n",
    "Loss is calculated between predictions and actual values.\n",
    "\n",
    "2. Backward Propagation (Backprop)\n",
    "\n",
    "Computes gradients of the loss function w.r.t. weights.\n",
    "Uses the chain rule to distribute errors back through layers.\n",
    "Weight Update using Gradient Descent\n",
    "\n",
    "Updates weights in the opposite direction of the gradient.\n",
    "\n",
    "##### Types of Gradient Descent\n",
    "1. Batch Gradient Descent: Uses the entire dataset to compute gradients.\n",
    "2. Stochastic Gradient Descent (SGD): Uses one data point at a time, making updates noisier but faster.\n",
    "3. Mini-batch Gradient Descent: Uses small batches of data, balancing speed and stability.\n",
    "\n",
    "##### Learning Rate & Optimization Techniques\n",
    "- Learning Rate (α): Controls step size in gradient descent.\n",
    "- Advanced Optimizers:\n",
    "    - Adam (Adaptive Moment Estimation)\n",
    "    - RMSprop (Root Mean Square Propagation)\n",
    "    - Momentum-based GD (Accelerates learning)\n",
    "\n",
    "##### Overfitting & Regularization (P.C 8.2.2)\n",
    "1. What is Overfitting?\n",
    " - Overfitting: Model memorizes training data but performs poorly on new data.\n",
    " - Underfitting: Model is too simple and fails to learn patterns.\n",
    "\n",
    "2. Regularization Techniques\n",
    " - L1 & L2 Regularization (Weight Decay)\n",
    "        - L1 (Lasso Regression): Encourages sparsity in weights.\n",
    "        - L2 (Ridge Regression): Reduces large weight values to prevent overfitting.\n",
    " - Dropout\n",
    "Randomly drops neurons during training to improve generalization.\n",
    " - Batch Normalization\n",
    "Normalizes inputs to each layer, accelerating training.\n",
    "- Data Augmentation\n",
    "Modifies training images (rotation, flipping, etc.) to increase dataset variety.\n",
    "- Early Stopping\n",
    "Stops training when validation loss increases.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
